# -*- coding: utf-8 -*-
"""Wendy's Offer Design Agent - Final - Gaurav

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AVuiColtGZNT-V-9TZa-fIbExQFelU5P

#1. Install Packages
"""

#!pip install langchain-openai
#!pip install langchain-community
#!pip install faker

#"""# **2. Import and Setup**"""

import pandas as pd # For data manipulation and analysis
import numpy as np # For numerical operations
import random # For generating random data
import json # For working with JSON data
from typing import TypedDict, List # For type hinting, especially for state management
from faker import Faker # For generating fake data for simulation
from openai import OpenAI # For interacting with OpenAI-compatible LLMs
#from google.colab import userdata # For securely accessing Colab secrets
from datetime import date # For date operations
from langgraph.graph import StateGraph, START, END # For building the LangGraph agent orchestration

# Accessing API key from Colab Secrets (ensure 'OPENAI_API_KEY' is set in your secrets tab)
openai_api_key = userdata.get('OPENAI_API_KEY')
# Initialize the OpenAI client with the API key and custom base URL
client = OpenAI(api_key=openai_api_key, base_url="https://api.ai-gateway.tigeranalytics.com")
# Initialize Faker for generating synthetic data
fake = Faker()
# Define a fixed 'today's date' for consistent data generation
TODAY = date(2026, 1, 24)
# Define the model name to be used for LLM calls
MODEL_NAME = "gemini-2.5-flash"

#"""#3. Define Master State for the System"""

# Define the master state for the entire system using TypedDict for schema enforcement
class MasterState(TypedDict):
    # Core inputs that can be passed to the graph initially or updated by nodes
    wendys_active: List[str] # List of active Wendy's promotions
    competitor_intel: dict # Detailed metadata for traceability and summary of competitor activities
    customer_insights: str # Summary of customer behavioral insights
    raw_market_signals: pd.DataFrame
    market_trends: List[dict]          # Structured trend signals
    market_context_windows: List[dict] # Timing & situational relevance
    market_trends_summary: str         # Narrative summary for creative agent
    raw_concepts: str # Raw, unstructured offer concepts generated by the creative agent
    # Structured keys to hold synchronized data after processing
    structured_concepts: List[dict] # Refined offer concepts in a structured (JSON) format
    final_report_text: str # Introductory text for the final report
    prioritization_table: pd.DataFrame # DataFrame for visualizing offer prioritization

    # --- Trend â†’ Mechanic Constraints ---
TREND_MECHANIC_MAP = {
    "Gamified Rewards": "challenge, streak, or unlock mechanic",
    "Late-Night Value": "time-boxed or after-hours unlock",
    "Surprise & Delight": "randomized reward trigger",
    "Subscription Meal Bundles": "recurring opt-in benefit",
    "App-Exclusive Perks": "mobile-only gated access"
}

#"""#4. Agent #1 - Building Competitor Intelligence Agent

### 4a. Define the Nodes - Competitor Intelligence Logic
#"""

def competitor_analyst_node(state: MasterState):
    """Calculates advanced Threat Scores: Saturation + Velocity + Recency Bias for competitor offers."""

    print("âœ… Competitor Analyst RUNNING")

    # Simulate competitor data generation
    records = []
    for _ in range(500):
        records.append({
            "id": fake.uuid4()[:8], # Unique ID for traceability
            "brand": random.choice(["McDonald's", "Burger King", "Taco Bell"]), # Competitor brand
            "mechanic": random.choice(["BOGO", "Gamified App Challenge", "Loyalty Multiplier"]), # Offer mechanic
            "obs_date": pd.to_datetime(fake.date_between(start_date='-60d', end_date=TODAY)) # Observation date
        })
    df = pd.DataFrame(records)
    # Assign a weight to each record based on recency (more recent = higher weight)
    df['weight'] = np.exp(-0.05 * (pd.Timestamp(TODAY) - df['obs_date']).dt.days)

    # Identify competitor mechanics that Wendy's is NOT currently active in (gaps)
    gaps = df[~df['mechanic'].isin(state["wendys_active"])]
    threats = []
    # Group by mechanic to calculate threat scores
    for mech, group in gaps.groupby('mechanic'):
        top_brand = group.groupby('brand')['weight'].sum().idxmax() # Identify the leading competitor for this mechanic
        score = round((group['weight'].sum() / 5), 1) # Calculate a threat score
        # Inclusion of Traceability ID for "Signal Quality" score
        trace_id = group.sort_values('weight', ascending=False)['id'].iloc[0] # Get ID of the most relevant record
        threats.append(f"{mech} driven by {top_brand} (Threat: {score}/10) [Ref ID: {trace_id}]")

    # Return the summary of threats and the raw data for potential further analysis
    return {"competitor_intel": {"summary": "\n".join(threats), "raw": gaps.to_dict()}}

"""#5. Agent #2 - Building Customer Insights Agent

### 5a. Define the Nodes - Customer Insights Logic
"""

def customer_analyst_node(state: MasterState):
    """Analyzes behavioral signals to identify high-redemption segments and customer preferences."""

    print("âœ… Customer Analyst RUNNING")

    # (Simplified internal analysis based on provided feedback templates for demonstration)
    insights = [
        "Value-Oriented Mobile Users redeem app offers 1.002x more often.",
        "Efficient Drive-Thru Diners redeem 1.004x more often via Drive-Thru."
    ]
    # Return the aggregated customer insights as a single string
    return {"customer_insights": "\n".join(insights)}

"""#6. Agent #3 - Building Market Trends Agent

### 6a. Define the Nodes - Market Trends Logic

# **NEW NODE A â€” Market Context Signal Generator**
"""

def market_context_generator(state: MasterState):
    records = []

    trend_types = [
        "Gamified Rewards",
        "Subscription Meal Bundles",
        "Surprise & Delight",
        "Late-Night Value",
        "App-Exclusive Perks"
    ]

    seasons = ["Winter", "Spring", "Summer", "Fall"]
    dayparts = ["Breakfast", "Lunch", "Dinner", "Late Night"]
    situations = ["Cold Weather", "Payday", "Commute", "Weekend"]
    sources = ["Reddit", "TikTok", "Press", "Food Blogs"]

    for _ in range(900):
        records.append({
            "trend_type": random.choice(trend_types),
            "season": random.choice(seasons),
            "daypart": random.choice(dayparts),
            "situation": random.choice(situations),
            "source": random.choice(sources),
            "observed_date": fake.date_between(start_date='-120d', end_date=TODAY)
        })

    return {"raw_market_signals": pd.DataFrame(records)}

"""# **Market Context Analyst (Structured Scoring)**"""

def market_context_analyst(state: MasterState):
    df = state["raw_market_signals"].copy()

    # Normalize dates
    df["observed_date"] = pd.to_datetime(df["observed_date"])
    df["days_ago"] = (pd.Timestamp(TODAY) - df["observed_date"]).dt.days

    # Recency decay weighting
    df["weight"] = np.exp(-0.05 * df["days_ago"])

    windows = []

    # Aggregate timing/context signals
    for keys, group in df.groupby(
        ["trend_type", "season", "daypart", "situation"]
    ):
        strength = group["weight"].sum()
        ref_id = group.index[0]  # lightweight traceability ID

        windows.append({
            "signal_id": f"CTX-{ref_id}",
            "trend": keys[0],
            "season": keys[1],
            "daypart": keys[2],
            "situation": keys[3],
            "timing_strength": round(strength, 2)
        })

    # Guardrail (prevents divide-by-zero)
    if not windows:
        return {"market_context_windows": []}

    max_strength = max(w["timing_strength"] for w in windows)

    # Score + classify
    for w in windows:
        w["relevance_score"] = round(
            (w["timing_strength"] / max_strength) * 10, 1
        )
        w["confidence"] = round(
            min(1.0, w["timing_strength"] / (0.75 * max_strength)), 2
        )
        w["action"] = (
            "Act Now" if w["relevance_score"] >= 7
            else "Monitor"
        )

    # âœ… NEW: Cap to Top 5 Most Relevant Windows
    windows = sorted(
        windows,
        key=lambda x: x["relevance_score"],
        reverse=True
    )[:5]

    return {
        "market_context_windows": windows
    }

"""# **Convert Structured Context â†’ Narrative Trends**"""

def market_trends_narrator(state: MasterState):
    context = json.dumps(state["market_context_windows"], indent=2)

    print("âœ… market_trends_narrator RUNNING")

    prompt = f"""
    You are Wendyâ€™s Market Strategist.

    Using the timing and context signals below:
    - Summarize the top emerging trends
    - Explain WHEN and WHY they matter
    - Use consumer language and value cues

    DATA:
    {context}
    """

    res = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )

    return {"market_trends_summary": res.choices[0].message.content}

def context_ready_gate(state: MasterState):
    """
    Synchronization node.
    Ensures all required upstream context is present
    before offer design runs.
    """
    return {}

"""#7. Agent #4 - Building Offer Design Orchestrator

### 7a. Creative Designer (Creativity & Differentiation)
"""

def offer_designer_node(state: MasterState):

    print("âœ… Offer Designer RUNNING")

    assert "market_trends_summary" in state, \
        f"Missing market_trends_summary. Available keys: {list(state.keys())}"

    prompt = f"""
You are Wendy's Lead Creative Strategist.

Use the following intelligence signals to design differentiated offers.

COMPETITOR GAPS:
{state['competitor_intel']['summary']}

CUSTOMER INSIGHTS:
{state['customer_insights']}

TRENDS & CONTEXT:
{state['market_trends_summary']}

TOP SIGNALS (with evidence IDs):
{json.dumps(state["market_context_windows"], indent=2)}

MECHANIC CONSTRAINTS BY TREND:
{json.dumps(TREND_MECHANIC_MAP, indent=2)}

Constraints:
- Each offer MUST explicitly reference at least one signal_id
- The mechanic MUST align with the associated trend type
- Do NOT reuse standard discount formats (e.g., % off, $ off)

Task:
Design 2 original Wendy's offers.

Rules:
- One offer must be a DEFENSIVE response
- One offer must be a FIRST-TO-MARKET creative pivot

OUTPUT FORMAT (STRICT):
Name:
Why:
Strategy: Defensive | First-to-Market
Evidence Signal IDs:

Example:
Evidence Signal IDs: CTX-12, CTX-44
"""

    res = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )

    return {"raw_concepts": res.choices[0].message.content}

"""### 7b. Critique Loop (Agent Collaboration)"""

def brand_validator_node(state: MasterState):
    """Refines raw concepts with Wendy's brand voice and returns them in a structured JSON format."""
    # Construct a prompt to refine concepts and enforce a specific JSON output format
    prompt = f"""
    Refine these concepts with Wendy's witty brand voice: {state['raw_concepts']}

    RETURN ONLY A JSON OBJECT in this format:
    {{
      "report_intro": "Intro text here...",
      "offers": [
        {{
          "name": "The Wendy's Daily Drip Deal",
          "witty_rationale": "Rationale text...",
          "type": "Defensive",
          "evidence_signals": ["CTX-12"],
          "feasibility": 9.0,
          "impact": 8.5
        }},
        ...
      ]
    }}
    """
    # Call the LLM, specifying JSON object as the desired response format
    res = client.chat.completions.create(
        model=MODEL_NAME,
        response_format={ "type": "json_object" }, # Ensures valid JSON output
        messages=[{"role": "user", "content": prompt}]
    )

    # Parse the JSON string from the LLM response
    data = json.loads(res.choices[0].message.content)
    # Update the state with structured concepts and the report introduction
    return {
        "structured_concepts": data["offers"],
        "final_report_text": data["report_intro"]
    }

"""### 7c. Visualization Scorecard"""

def visualization_node(state: MasterState):
    """Dynamically builds a prioritization table using the EXACT names and scores from the Validator Agent's output."""
    # Retrieve the structured concepts from the current state
    concepts = state["structured_concepts"]

    table_data = []
    # Iterate through each structured concept to prepare data for the DataFrame
    for item in concepts:
        table_data.append({
            "Concept": item["name"], # Use the refined concept name
            "Feasibility": item["feasibility"],
            "Impact": item["impact"],
            "Confidence": round((item["impact"] + item["feasibility"]) / 20, 2),
            "Type": item["type"]
        })

    # Create a Pandas DataFrame from the prepared data
    return {"prioritization_table": pd.DataFrame(table_data)}

"""#8. Build and Compile the Graph

### 8a. Build the Graph Architecture
"""

builder = StateGraph(MasterState) # Initialize the graph with the defined MasterState schema

builder.add_node("ready", context_ready_gate)


# Add all agent nodes to the graph
builder.add_node("comp", competitor_analyst_node) # Node for Competitor Intelligence
builder.add_node("cust", customer_analyst_node) # Node for Customer Insights
builder.add_node("mkt_gen", market_context_generator)
builder.add_node("mkt_ctx", market_context_analyst)
builder.add_node("trend", market_trends_narrator)
builder.add_node("design", offer_designer_node) # Node for Offer Design (Creative Strategist)
builder.add_node("validate", brand_validator_node) # Node for Brand Validation and Structuring
builder.add_node("viz", visualization_node) # Node for Visualization/Prioritization Table

"""### 8b. Orchestration Flow"""

# Step 1: Define edges for parallel execution of initial analytical agents
# All three analytical agents start their work concurrently from the initial state.
# Parallel starts
builder.add_edge(START, "comp")
builder.add_edge(START, "cust")
builder.add_edge(START, "mkt_gen")

# Market context chain
builder.add_edge("mkt_gen", "mkt_ctx")
builder.add_edge("mkt_ctx", "trend")

# Step 2: Define edges for the orchestrator (Offer Designer) and subsequent validation
# All three analytical agents' outputs feed into the Offer Designer.
# All intelligence must finish first
# Design must wait for trend (hard dependency)
builder.add_edge("trend", "design")

# Downstream
builder.add_edge("design", "validate")
builder.add_edge("validate", "viz")
builder.add_edge("viz", END)

# Step 3: Link the Brand Validator to the Visualizer and then to the end of the graph
# The structured concepts from the Validator are used to create the visualization.
builder.add_edge("validate", "viz")
# The graph concludes after the visualization is prepared.
builder.add_edge("viz", END)

"""#9. Compile the Final App"""

app = builder.compile()

"""#2. Import and SetUp"""

import pandas as pd # For data manipulation and analysis
import numpy as np # For numerical operations
import random # For generating random data
import json # For working with JSON data
from typing import TypedDict, List # For type hinting, especially for state management
from faker import Faker # For generating fake data for simulation
from openai import OpenAI # For interacting with OpenAI-compatible LLMs
from google.colab import userdata # For securely accessing Colab secrets
from datetime import date # For date operations
from langgraph.graph import StateGraph, START, END # For building the LangGraph agent orchestration

# Accessing API key from Colab Secrets (ensure 'OPENAI_API_KEY' is set in your secrets tab)
openai_api_key = userdata.get('OPENAI_API_KEY')
# Initialize the OpenAI client with the API key and custom base URL
client = OpenAI(api_key=openai_api_key, base_url="https://api.ai-gateway.tigeranalytics.com")
# Initialize Faker for generating synthetic data
fake = Faker()
# Define a fixed 'today's date' for consistent data generation
TODAY = date(2026, 1, 24)
# Define the model name to be used for LLM calls
MODEL_NAME = "gemini-2.5-flash"

"""#3. Define Master State for the System"""

# Define the master state for the entire system using TypedDict for schema enforcement
class MasterState(TypedDict):
    # Core inputs that can be passed to the graph initially or updated by nodes
    wendys_active: List[str] # List of active Wendy's promotions
    competitor_intel: dict # Detailed metadata for traceability and summary of competitor activities
    customer_insights: str # Summary of customer behavioral insights
    raw_market_signals: pd.DataFrame
    market_trends: List[dict]          # Structured trend signals
    market_context_windows: List[dict] # Timing & situational relevance
    market_trends_summary: str         # Narrative summary for creative agent
    raw_concepts: str # Raw, unstructured offer concepts generated by the creative agent
    # Structured keys to hold synchronized data after processing
    structured_concepts: List[dict] # Refined offer concepts in a structured (JSON) format
    final_report_text: str # Introductory text for the final report
    prioritization_table: pd.DataFrame # DataFrame for visualizing offer prioritization

    # --- Trend â†’ Mechanic Constraints ---
TREND_MECHANIC_MAP = {
    "Gamified Rewards": "challenge, streak, or unlock mechanic",
    "Late-Night Value": "time-boxed or after-hours unlock",
    "Surprise & Delight": "randomized reward trigger",
    "Subscription Meal Bundles": "recurring opt-in benefit",
    "App-Exclusive Perks": "mobile-only gated access"
}

"""#4. Agent #1 - Building Competitor Intelligence Agent

### 4a. Define the Nodes - Competitor Intelligence Logic
"""

def competitor_analyst_node(state: MasterState):
    """Calculates advanced Threat Scores: Saturation + Velocity + Recency Bias for competitor offers."""

    print("âœ… Competitor Analyst RUNNING")

    # Simulate competitor data generation
    records = []
    for _ in range(500):
        records.append({
            "id": fake.uuid4()[:8], # Unique ID for traceability
            "brand": random.choice(["McDonald's", "Burger King", "Taco Bell"]), # Competitor brand
            "mechanic": random.choice(["BOGO", "Gamified App Challenge", "Loyalty Multiplier"]), # Offer mechanic
            "obs_date": pd.to_datetime(fake.date_between(start_date='-60d', end_date=TODAY)) # Observation date
        })
    df = pd.DataFrame(records)
    # Assign a weight to each record based on recency (more recent = higher weight)
    df['weight'] = np.exp(-0.05 * (pd.Timestamp(TODAY) - df['obs_date']).dt.days)

    # Identify competitor mechanics that Wendy's is NOT currently active in (gaps)
    gaps = df[~df['mechanic'].isin(state["wendys_active"])].copy()
    threats = []
    # Group by mechanic to calculate threat scores
    for mech, group in gaps.groupby('mechanic'):
        top_brand = group.groupby('brand')['weight'].sum().idxmax() # Identify the leading competitor for this mechanic
        score = round(min(10, (group['weight'].sum() / 5)), 1) # Calculate a threat score and cap at 10
        # Inclusion of Traceability ID for "Signal Quality" score
        trace_id = group.sort_values('weight', ascending=False)['id'].iloc[0] # Get ID of the most relevant record
        threats.append(f"{mech} driven by {top_brand} (Threat: {score}/10) [Ref ID: {trace_id}]")

    # Return the summary of threats and the raw data for potential further analysis
    return {"competitor_intel": {"summary": "\n".join(threats), "raw": gaps.to_dict()}}

"""#5. Agent #2 - Building Customer Insights Agent

### 5a. Define the Nodes - Customer Insights Logic
"""

def customer_analyst_node(state: MasterState):
    """Analyzes behavioral signals to identify high-redemption segments and customer preferences."""

    print("âœ… Customer Analyst RUNNING")

    # (Simplified internal analysis based on provided feedback templates for demonstration)
    insights = [
        "Value-Oriented Mobile Users redeem app offers 1.002x more often.",
        "Efficient Drive-Thru Diners redeem 1.004x more often via Drive-Thru."
    ]
    # Return the aggregated customer insights as a single string
    return {"customer_insights": "\n".join(insights)}

"""#6. Agent #3 - Building Market Trends Agent

### 6a. Define the Nodes - Market Trends Logic

# **NEW NODE A â€” Market Context Signal Generator**
"""

def market_context_generator(state: MasterState):
    records = []

    trend_types = [
        "Gamified Rewards",
        "Subscription Meal Bundles",
        "Surprise & Delight",
        "Late-Night Value",
        "App-Exclusive Perks"
    ]

    seasons = ["Winter", "Spring", "Summer", "Fall"]
    dayparts = ["Breakfast", "Lunch", "Dinner", "Late Night"]
    situations = ["Cold Weather", "Payday", "Commute", "Weekend"]
    sources = ["Reddit", "TikTok", "Press", "Food Blogs"]

    for _ in range(900):
        records.append({
            "trend_type": random.choice(trend_types),
            "season": random.choice(seasons),
            "daypart": random.choice(dayparts),
            "situation": random.choice(situations),
            "source": random.choice(sources),
            "observed_date": fake.date_between(start_date='-120d', end_date=TODAY)
        })

    return {"raw_market_signals": pd.DataFrame(records)}

"""# **Market Context Analyst (Structured Scoring)**"""

def market_context_analyst(state: MasterState):
    df = state["raw_market_signals"].copy()

    # Normalize dates
    df["observed_date"] = pd.to_datetime(df["observed_date"])
    df["days_ago"] = (pd.Timestamp(TODAY) - df["observed_date"]).dt.days

    # Recency decay weighting
    df["weight"] = np.exp(-0.05 * df["days_ago"])

    windows = []

    # Aggregate timing/context signals
    for keys, group in df.groupby(
        ["trend_type", "season", "daypart", "situation"]
    ):
        strength = group["weight"].sum()
        ref_id = group.index[0]  # lightweight traceability ID

        windows.append({
            "signal_id": f"CTX-{ref_id}",
            "trend": keys[0],
            "season": keys[1],
            "daypart": keys[2],
            "situation": keys[3],
            "timing_strength": round(strength, 2)
        })

    # Guardrail (prevents divide-by-zero)
    if not windows:
        return {"market_context_windows": []}

    max_strength = max(w["timing_strength"] for w in windows)

    # Score + classify
    for w in windows:
        w["relevance_score"] = round(
            (w["timing_strength"] / max_strength) * 10, 1
        )
        w["confidence"] = round(
            min(1.0, w["timing_strength"] / (0.75 * max_strength)), 2
        )
        w["action"] = (
            "Act Now" if w["relevance_score"] >= 7
            else "Monitor"
        )

    # âœ… NEW: Cap to Top 5 Most Relevant Windows
    windows = sorted(
        windows,
        key=lambda x: x["relevance_score"],
        reverse=True
    )[:5]

    return {
        "market_context_windows": windows
    }

"""# **Convert Structured Context â†’ Narrative Trends**"""

def market_trends_narrator(state: MasterState):
    context = json.dumps(state["market_context_windows"], indent=2)

    print("âœ… market_trends_narrator RUNNING")

    prompt = f"""
    You are Wendyâ€™s Market Strategist.

    Using the timing and context signals below:
    - Summarize the top emerging trends
    - Explain WHEN and WHY they matter
    - Use consumer language and value cues

    DATA:
    {context}
    """

    res = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )

    return {"market_trends_summary": res.choices[0].message.content}

def context_ready_gate(state: MasterState):
    """
    Synchronization node.
    Ensures all required upstream context is present
    before offer design runs.
    """
    return {}

"""#7. Agent #4 - Building Offer Design Orchestrator

### 7a. Creative Designer (Creativity & Differentiation)
"""

def offer_designer_node(state: MasterState):

    print("âœ… Offer Designer RUNNING")

    assert "market_trends_summary" in state, \
        f"Missing market_trends_summary. Available keys: {list(state.keys())}"

    prompt = f"""
You are Wendy's Lead Creative Strategist.

Use the following intelligence signals to design differentiated offers.

COMPETITOR GAPS:
{state['competitor_intel']['summary']}

CUSTOMER INSIGHTS:
{state['customer_insights']}

TRENDS & CONTEXT:
{state['market_trends_summary']}

TOP SIGNALS (with evidence IDs):
{json.dumps(state["market_context_windows"], indent=2)}

MECHANIC CONSTRAINTS BY TREND:
{json.dumps(TREND_MECHANIC_MAP, indent=2)}

Constraints:
- Each offer MUST explicitly reference at least one signal_id
- The mechanic MUST align with the associated trend type
- Do NOT reuse standard discount formats (e.g., % off, $ off)

Task:
Design 2 original Wendy's offers.

Rules:
- One offer must be a DEFENSIVE response
- One offer must be a FIRST-TO-MARKET creative pivot

OUTPUT FORMAT (STRICT):
Name:
Why:
Strategy: Defensive | First-to-Market
Evidence Signal IDs:

Example:
Evidence Signal IDs: CTX-12, CTX-44
"""

    res = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}]
    )

    return {"raw_concepts": res.choices[0].message.content}

"""### 7b. Critique Loop (Agent Collaboration)"""

def brand_validator_node(state: MasterState):
    """Refines raw concepts with Wendy's brand voice and returns them in a structured JSON format."""
    # Construct a prompt to refine concepts and enforce a specific JSON output format
    prompt = f"""
    Refine these concepts with Wendy's witty brand voice: {state['raw_concepts']}

    RETURN ONLY A JSON OBJECT in this format:
    {{
      "report_intro": "Intro text here...",
      "offers": [
        {{
          "name": "The Wendy's Daily Drip Deal",
          "witty_rationale": "Rationale text...",
          "type": "Defensive",
          "evidence_signals": ["CTX-12"],
          "feasibility": 9.0,
          "impact": 8.5
        }},
        ...
      ]
    }}
    """
    # Call the LLM, specifying JSON object as the desired response format
    res = client.chat.completions.create(
        model=MODEL_NAME,
        response_format={ "type": "json_object" }, # Ensures valid JSON output
        messages=[{"role": "user", "content": prompt}]
    )

    # Parse the JSON string from the LLM response
    data = json.loads(res.choices[0].message.content)
    # Update the state with structured concepts and the report introduction
    return {
        "structured_concepts": data["offers"],
        "final_report_text": data["report_intro"]
    }

"""### 7c. Visualization Scorecard"""

def visualization_node(state: MasterState):
    """Dynamically builds a prioritization table using the EXACT names and scores from the Validator Agent's output."""
    # Retrieve the structured concepts from the current state
    concepts = state["structured_concepts"]

    table_data = []
    # Iterate through each structured concept to prepare data for the DataFrame
    for item in concepts:
        table_data.append({
            "Concept": item["name"], # Use the refined concept name
            "Feasibility": item["feasibility"],
            "Impact": item["impact"],
            "Confidence": round((item["impact"] + item["feasibility"]) / 20, 2),
            "Type": item["type"]
        })

    # Create a Pandas DataFrame from the prepared data
    return {"prioritization_table": pd.DataFrame(table_data)}

"""#8. Build and Compile the Graph

### 8a. Build the Graph Architecture
"""

builder = StateGraph(MasterState) # Initialize the graph with the defined MasterState schema

builder.add_node("ready", context_ready_gate)


# Add all agent nodes to the graph
builder.add_node("comp", competitor_analyst_node) # Node for Competitor Intelligence
builder.add_node("cust", customer_analyst_node) # Node for Customer Insights
builder.add_node("mkt_gen", market_context_generator)
builder.add_node("mkt_ctx", market_context_analyst)
builder.add_node("trend", market_trends_narrator)
builder.add_node("design", offer_designer_node) # Node for Offer Design (Creative Strategist)
builder.add_node("validate", brand_validator_node) # Node for Brand Validation and Structuring
builder.add_node("viz", visualization_node) # Node for Visualization/Prioritization Table

"""### 8b. Orchestration Flow"""

# Step 1: Define edges for parallel execution of initial analytical agents
# All three analytical agents start their work concurrently from the initial state.
# Parallel starts
builder.add_edge(START, "comp")
builder.add_edge(START, "cust")
builder.add_edge(START, "mkt_gen")

# Market context chain
builder.add_edge("mkt_gen", "mkt_ctx")
builder.add_edge("mkt_ctx", "trend")

# Step 2: Define edges for the orchestrator (Offer Designer) and subsequent validation
# All three analytical agents' outputs feed into the Offer Designer.
# All intelligence must finish first
# Design must wait for trend (hard dependency)
builder.add_edge("trend", "design")

# Downstream
builder.add_edge("design", "validate")
builder.add_edge("validate", "viz")
builder.add_edge("viz", END)

# Step 3: Link the Brand Validator to the Visualizer and then to the end of the graph
# The structured concepts from the Validator are used to create the visualization.
builder.add_edge("validate", "viz")
# The graph concludes after the visualization is prepared.
builder.add_edge("viz", END)

"""#9. Compile the Final App"""

app = builder.compile()

"""## Wendyâ€™s Signal-to-Offer Engine

This system converts fragmented market signals into launch-ready offers.

**How it works:**
1. Detects competitor whitespace
2. Identifies who will redeem
3. Determines when & why offers matter
4. Designs differentiated offers
5. Validates brand fit & feasibility
**bold text**

#10. Final Execution
"""

# 1. Initialize the system with Wendy's current focus
# This list is used by the Competitor Intelligence Agent to determine 'whitespaces'
initial_state = {"wendys_active": ["Biggie Bag", "4 for $4"]}

# 2. Invoke the unified LangGraph orchestrator
# This triggers parallel analysis from all three specialized agents followed by synthesis
result = app.invoke(initial_state)

# 3. Display Individual Agent Outputs for Signal Traceability
print("="*60)
print("ðŸ”Ž AGENT 1: COMPETITOR INTELLIGENCE OUTPUT")
print("-"*60)
# Displays recency-biased threat scores and competitor gaps
print(result["competitor_intel"]["summary"])

print("\n" + "="*60)
print("ðŸ‘¤ AGENT 2: CUSTOMER INSIGHTS OUTPUT")
print("-"*60)
# Displays behavioral signals and high-redemption segment profiles
print(result["customer_insights"])

print("\n" + "="*60)
print("ðŸ“ˆ AGENT 3: MARKET TRENDS RADAR")
print("-"*60)
# Displays rising themes and social velocity metrics
print(result["market_trends_summary"])

print("### AGENT COLLABORATION & DESIGN REPORT ###")
print(result["final_report_text"])

# Loop through structured concepts to print the witty descriptions
for offer in result["structured_concepts"]:
    print(f"\n--- {offer['name']} ---")
    print(offer["witty_rationale"])

print("\n### EXECUTIVE PRIORITIZATION SCORECARD ###")
# The names here are now guaranteed to match the text above

print("\n### EXECUTIVE DECISION VIEW ###")
print("Higher impact + feasibility should be prioritized for immediate launch.\n")


display(result["prioritization_table"].style.background_gradient(cmap='YlOrRd'))
